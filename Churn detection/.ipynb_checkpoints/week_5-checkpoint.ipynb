{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Peer-graded Assignment: Эксперименты с моделью\n",
    "\n",
    "На прошлой неделе вы поучаствовали в соревновании на kaggle и, наверняка, большинство успешно справилось с прохождением baseline, а значит пора двигаться дальше - заняться оптимизацией модели, провести серию экспериментов и построить сильное финальное решения.\n",
    "\n",
    "В этом задании вам нужно провести ряд эскпериментов, оценить качество полученных в процессе экспериментирования моделей и выбрать лучшее решение. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание будет оцениваться на основании загруженного jupyther notebook и развернутых ответов на поставленные вопросы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Инструкции"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. Начнем с простого. Давайте оценим как много объектов действительно нужно для построения качественной модели. Для обучения доступна достаточно большая выборка и может так оказаться, что начиная с некоторого момента рост размера обучающей выборки перестает влиять на качество модели. Постройте кривые обучения, обучая модель на выборках разного размера начиная с небольшого количество объектов в обучающей выборке и постепенно наращивая её размер с некоторым шагом. Обратите внимание на `sklearn.model_selection.learning_curve`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#загрузка данных\n",
    "import pandas as pd\n",
    "data_source = pd.read_csv('../Data/orange_small_churn_data.txt')\n",
    "labels = pd.read_csv('../Data/orange_small_churn_labels.txt', header=None)\n",
    "data_source['label'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# произведем преобразование и фильтрацию признаков (на основе прошлых недель)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "def preprocess(data_train, filling_method, cat_method='dummy'):\n",
    "    data = data_train.copy()\n",
    "    #Отбросим признаки, у которых больше половины значений незаполнены\n",
    "    bad_features = data.columns[data.isnull().mean(axis=0)>0.5]\n",
    "    data = data.drop(bad_features, axis=1)\n",
    "    \n",
    "    #Рассмотрим отдельно вещественные и категориальные признаки\n",
    "    all_real_features = [\"Var\"+str(i) for i in xrange(1, 191)]\n",
    "    real_features = data.columns[data.columns.isin(all_real_features)]\n",
    "    cat_features = data.columns[~data.columns.isin(all_real_features+['label'])]\n",
    "    \n",
    "    #В вещественных признаках заменим пропуски на средние значения признаков и произведем стандартизацию признаков\n",
    "    filling_values = filling_method(data[real_features], axis=0)\n",
    "    data[real_features] = data[real_features].fillna(filling_values)\n",
    "    sc = StandardScaler()\n",
    "    data[real_features] = sc.fit_transform(data[real_features])\n",
    "    \n",
    "    #В категориальных признаках отбросим те из них, которые имеют слишком много категорий\n",
    "    num_cat = np.array([np.unique(data[feat]).shape[0] for feat in cat_features])\n",
    "    bad_cat_features = cat_features[num_cat>100]\n",
    "    data = data.drop(bad_cat_features, axis=1)\n",
    "    cat_features = cat_features[~cat_features.isin(bad_cat_features)]\n",
    "    \n",
    "    #В категориальных признаках произведем dummy кодирование, при этом пропуск будем расценивать как еще одну категорию\n",
    "    if cat_method == 'dummy':\n",
    "        data = pd.get_dummies(data, dummy_na=True, columns = cat_features, drop_first=True)\n",
    "    elif cat_method == 'le':\n",
    "        le = LabelEncoder()\n",
    "        for feat in cat_features:\n",
    "            data[feat] = le.fit_transform(data[feat])\n",
    "    \n",
    "    #добавим еще тройку категориальных признаков, которые (как мы ранее выяснили) имеют высокую корреляция с целевым признаком. Но применим к ним LabelEncoder, поскольку они имеют слишком много категорий\n",
    "    corr_cat_features = ['Var199', 'Var216', 'Var192']\n",
    "    le = LabelEncoder()\n",
    "    for feat in corr_cat_features:\n",
    "        data_train[feat] = data_train[feat].fillna('NaN')\n",
    "        data[feat] = le.fit_transform(data_train[feat])\n",
    "    \n",
    "    return data\n",
    "\n",
    "data = preprocess(data_source, pd.DataFrame.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 388)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data.drop('label', axis = 1)\n",
    "y = data.label\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda2\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PR AUC for logistic regression: 0.125507083078\n"
     ]
    }
   ],
   "source": [
    "#построим кривую обучения\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "train_sizes = np.arange(0.05, 1.05, 0.05)\n",
    "\n",
    "#в качестве классификатора возьмем LogisticRegression\n",
    "from sklearn.metrics import average_precision_score, make_scorer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import cross_val_score, StratifiedKFold\n",
    "\n",
    "lr = LogisticRegression()\n",
    "scorer = make_scorer(average_precision_score, needs_threshold=True)\n",
    "\n",
    "#сначала оценим качество модели на всей выборке\n",
    "scores = cross_val_score(lr, X, y, scoring=scorer, cv=StratifiedKFold(y, n_folds=5))\n",
    "print \"PR AUC for logistic regression: {}\".format(np.mean(scores))\n",
    "\n",
    "#построим кривую обучения\n",
    "t_scores = learning_curve(lr, X, y, train_sizes=train_sizes, scoring=scorer, cv=StratifiedKFold(y, n_folds=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0xde02eb8>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtMAAAHVCAYAAAAzRXexAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xf6f4b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(t_scores[0], t_scores[1].mean(axis=1))\n",
    "plt.plot(t_scores[0], t_scores[2].mean(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод: по данным кривым нельзя с уверенностью сказать, что можно обучаться по меньшему размеру выборки. Кривые до конца продолжают сближение, а значит будем использовать для обучения всю выборку."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. Часто несбалансированные по классам выборки приводят к различным проблемам при обучении моделей. Давайте попробуем по-разному обработать выборку, поиграть с распределением объектов по классам и сделать выводы о том, как соотношение классов влияет на качество модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1\\. Задайте веса объектам так, чтобы соотношение классов с учетом весов объектов изменилось. Попробуйте не менее трёх различных вариантов весов. Меняются ли результаты классификации? Как это сказывается на качестве модели? Какой вариант выглядит наиболее оптимальным с точки зрения качества?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    37024\n",
       " 1     2976\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = y.value_counts()\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 1 вариант. Добавим увеличивающие веса только для объектов класса 1\n",
    "sample_weights1 = np.ones(data.shape[0])\n",
    "sample_weights1[data.label==1] = float(counts[-1])/counts[1]\n",
    "scores = cross_val_score(lr, X, y, scoring=scorer, cv=StratifiedKFold(y, n_folds=5), fit_params={'sample_weight': sample_weights1})\n",
    "print \"PR AUC for logistic regression with weights #1: {}\".format(np.mean(scores))\n",
    "\n",
    "# 2 вариант. Добавим уменьшающие веса только для объектов класса -1\n",
    "sample_weights2 = np.ones(data.shape[0])\n",
    "sample_weights2[data.label==-1] = float(counts[1])/counts[-1]\n",
    "scores = cross_val_score(lr, X, y, scoring=scorer, cv=StratifiedKFold(y, n_folds=5), fit_params={'sample_weight': sample_weights2})\n",
    "print \"PR AUC for logistic regression with weights #2: {}\".format(np.mean(scores))\n",
    "\n",
    "# 3 вариант. Добавим веса для объектов обоих классов обратно пропрционально их долям в выборке\n",
    "sample_weights3 = np.ones(data.shape[0])\n",
    "sample_weights3[data.label==-1] = 1./np.mean(y==-1)\n",
    "sample_weights3[data.label==1] = 1./np.mean(y==1)\n",
    "scores = cross_val_score(lr, X, y, scoring=scorer, cv=StratifiedKFold(y, n_folds=5), fit_params={'sample_weight': sample_weights3})\n",
    "print \"PR AUC for logistic regression with weights #3: {}\".format(np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В результате применения весов качество чуть-чуть подросло, 2 вариант выглядит наиболее оптимальным."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2\\. Примените к выборке технологию undersampling: для этого нужно убрать из обучения некоторое количество объектов большего класса таким образом, чтобы соотношение классов изменилось. Попробуйте не менее трёх различных вариантов undersampling (варианты могут отличаться как по количество отфильтрованных объектов, так и по принципу выборка объектов для отсеивания из выборки). Меняются ли результаты классификации? Как это сказывается на качестве модели? Какой вариант выглядит наиболее оптимальным с точки зрения качества?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([-1,  1], dtype=int64), array([11904,  2976], dtype=int64))\n",
      "(array([-1,  1], dtype=int64), array([11904,  2976], dtype=int64))\n",
      "(array([-1,  1], dtype=int64), array([11904,  2976], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "print np.unique(y_enn, return_counts=True)\n",
    "print np.unique(y_rs, return_counts=True)\n",
    "print np.unique(y_tl, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PR AUC for logistic regression with random under-sampling: 0.304379469718\n",
      "(14880L, 388L)\n",
      "PR AUC for logistic regression with under-sampling with nearest neighbours: 0.375370447283\n",
      "PR AUC for logistic regression with tomek links under-sampling: 0.304379469718\n"
     ]
    }
   ],
   "source": [
    "#Попробуем удалить объекты большего класса так, чтобы доля меньшего класса стала хотя бы 20%\n",
    "from imblearn.under_sampling import RandomUnderSampler, NearMiss, TomekLinks\n",
    "\n",
    "#1 вариант. Удаляем случайным образом\n",
    "rs = RandomUnderSampler(random_state=42, ratio={-1: counts[1]*4, 1: counts[1]})\n",
    "X_rs, y_rs = rs.fit_sample(X, y)\n",
    "scores = cross_val_score(lr, X_rs, y_rs, scoring=scorer, cv=StratifiedKFold(y_rs, n_folds=5))\n",
    "print \"PR AUC for logistic regression with random under-sampling: {}\".format(np.mean(scores))\n",
    "\n",
    "#2 вариант. Удаляем те объекты, которые не согласуются со своими соседями\n",
    "nm = NearMiss(ratio={-1: counts[1]*4, 1: counts[1]})\n",
    "X_nm, y_nm = enn.fit_sample(X, y)\n",
    "scores = cross_val_score(lr, X_nm, y_nm, scoring=scorer, cv=StratifiedKFold(y_nm, n_folds=5))\n",
    "print \"PR AUC for logistic regression with under-sampling with nearest neighbours: {}\".format(np.mean(scores))\n",
    "\n",
    "#3 вариант. Используем метод TomekLinks. При этом методе удаляются те объекты большего класса, для которых ближашим по расстоянию является объект другого класса\n",
    "tl = TomekLinks(random_state=42, ratio={-1: counts[1]*4, 1: counts[1]})\n",
    "X_tl, y_tl = rs.fit_sample(X, y)\n",
    "scores = cross_val_score(lr, X_tl, y_tl, scoring=scorer, cv=StratifiedKFold(y_tl, n_folds=5))\n",
    "print \"PR AUC for logistic regression with tomek links under-sampling: {}\".format(np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. Теперь перейдем к работе с признаками. Ранее вы реализовали несколько стратегий для обработки пропущенных значений. Сравните эти стратегии между собой с помощью оценки качества моделей кросс-валидации, построенных на датасетах с использованием различных стратегий. Как обработка пропущенных значений сказывается на качестве модели? Какой вариант выглядит наиболее оптимальным с точки зрения качества?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PR AUC for logistic regression with medians: 0.125231604934\n",
      "PR AUC for logistic regression with modes: 0.125606156456\n"
     ]
    }
   ],
   "source": [
    "# Ранее мы заполняли пропущенные значения средним, теперь попробуем заполнять медианой и модой, сравним качество с полученным ранее\n",
    "data_med = preprocess(data_source, pd.DataFrame.median)\n",
    "X_med = data_med.drop('label', axis = 1)\n",
    "y_med = data_med.label\n",
    "scores = cross_val_score(lr, X_med, y_med, scoring=scorer, cv=StratifiedKFold(y_med, n_folds=5))\n",
    "print \"PR AUC for logistic regression with medians: {}\".format(np.mean(scores))\n",
    "\n",
    "data_mod = preprocess(data_source, lambda data, axis: pd.DataFrame.mode(data, axis=axis, numeric_only=True).iloc[0])\n",
    "X_mod = data_mod.drop('label', axis = 1)\n",
    "y_mod = data_mod.label\n",
    "scores = cross_val_score(lr, X_mod, y_mod, scoring=scorer, cv=StratifiedKFold(y_mod, n_folds=5))\n",
    "print \"PR AUC for logistic regression with modes: {}\".format(np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. Также вы уже реализовали несколько стратегий для обработки категориальных признаков. Сравните эти стратегии между собой с помощью оценки качества моделей по кросс-валидации, построенных на датасетах с использованием различных стратегий. Как обработка категориальных признаков сказывается на качестве модели? Какой вариант выглядит наиболее оптимальным с точки зрения качества?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Ранее мы обрабатывали большинство категориальных признаков (кроме имеющих большое количество категорий) с помощью dummy кодирования.\n",
    "#Теперь попробуем вместо этого применить к ним LabelEncoder.\n",
    "data_le = preprocess(data_source, pd.DataFrame.mean, cat_method='le')\n",
    "X_le = data_le.drop('label', axis = 1)\n",
    "y_le = data_le.label\n",
    "scores = cross_val_score(lr, X_le, y_le, scoring=scorer, cv=StratifiedKFold(y_le, n_folds=5))\n",
    "print \"PR AUC for logistic regression with label encoder for all categorical data: {}\".format(np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. Все ли признаки оказались полезными для построения моделей? Проведите процедуру отбора признаков, попробуйте разные варианты отбора (обратите внимание на модуль `sklearn.feature_selection`). Например, можно выбрасывать случайные признаки или строить отбор на основе l1-регуляризации - отфильтровать из обучения признаки, которые получат нулевой вес при построении регрессии с l1-регуляризацией (`sklearn.linear_model.Lasso`). И всегда можно придумать что-то своё=) Попробуйте как минимум 2 различные стратегии, сравните результаты. Помог ли отбор признаков улучшить качество модели? Поясните свой ответ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6\\. Подберите оптимальные параметры модели. Обратите внимание, что в зависимости от того, как вы обработали исходные данные, сделали ли балансировку классов, сколько объектов оставили в обучающей выборке и др. оптимальные значения параметров могут меняться. Возьмите наилучшее из ваших решений на текущий момент и проведите процедуру подбора параметров модели (обратите внимание на `sklearn.model_selection.GridSearchCV`) Как подбор параметров повлиял на качество модели?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7\\. Предложите методику оценки того, какие признаки внесли наибольший вклад в модель (например, это могут быть веса в случае регрессии, а также большое количество моделей реализуют метод `feature_importances_` - оценка важности признаков). На основе предложенной методики проанализируйте, какие признаки внесли больший вклад в модель, а какие меньший?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LogisticRegression' object has no attribute 'coef_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-00d1c82c361d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'LogisticRegression' object has no attribute 'coef_'"
     ]
    }
   ],
   "source": [
    "lr.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8\\. Напоследок давайте посмотрим на объекты. На каких объектах достигается наибольшая ошибка классификации? Есть ли межу этими объектами что-то общее? Видны ли какие-либо закономерности? Предположите, почему наибольшая ошибка достигается именно на этих объектах. В данном случае \"наибольшую\" ошибку можно понимать как отнесение объекта с чужому классу с большой долей уверенности (с высокой вероятностью)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9\\. По итогам проведенных экспериментов постройте финальную решение - модель с наилучшим качеством. Укажите, какие преобразования данных, параметры и пр. вы выбрали для построения финальной модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10\\. Подумайте, можно ли еще улучшить модель? Что для этого можно сделать? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
