{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_train = pd.read_csv('../Data/orange_small_churn_data.txt')\n",
    "data_test = pd.read_csv('../Data/orange_small_churn_test_data.csv')\n",
    "labels = pd.read_csv('../Data/orange_small_churn_labels.txt', header=None)\n",
    "data_train['label'] = labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Работа с незаполненными значениями"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отбросим признаки, у которых больше половины значений незаполнены - их полезность сомнительна"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 70)\n"
     ]
    }
   ],
   "source": [
    "bad_features = data_train.columns[data_train.isnull().mean(axis=0)>0.5]\n",
    "data_train = data_train.drop(bad_features, axis=1)\n",
    "data_test = data_test.drop(bad_features, axis=1)\n",
    "print data_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим отдельно вещественные и категориальные признаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_real_features = [\"Var\"+str(i) for i in xrange(1, 191)]\n",
    "real_features = data_train.columns[data_train.columns.isin(all_real_features)]\n",
    "cat_features = data_train.columns[~data_train.columns.isin(all_real_features+['label'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В вещественных признаках заменим пропуски на средние значения признаков и произведем стандартизацию признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "means = data_train[real_features].mean(axis=0, skipna=True)\n",
    "data_train[real_features] = data_train[real_features].fillna(means)\n",
    "data_test[real_features] = data_test[real_features].fillna(means)\n",
    "sc = StandardScaler()\n",
    "data_train[real_features] = sc.fit_transform(data_train[real_features])\n",
    "data_test[real_features] = sc.transform(data_test[real_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В категориальных признаках отбросим те из них, которые имеют слишком много категорий. В качестве порога выбрано 100, при этом получается приемлемое количество признаков. Иначе сильно вероятно переобучение, учитывая размер выборки в 30000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "num_cat = np.array([np.unique(data_train[feat]).shape[0] for feat in cat_features])\n",
    "bad_cat_features = cat_features[num_cat>100]\n",
    "data_train = data_train.drop(bad_cat_features, axis=1)\n",
    "data_test = data_test.drop(bad_cat_features, axis=1)\n",
    "cat_features = cat_features[~cat_features.isin(bad_cat_features)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В категориальных признаках произведем dummy кодирование, при этом пропуск будем расценивать как еще одну категорию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 386)\n",
      "(10000, 352)\n"
     ]
    }
   ],
   "source": [
    "data_train = pd.get_dummies(data_train, dummy_na=True, columns = cat_features, drop_first=True)\n",
    "data_test = pd.get_dummies(data_test, dummy_na=True, columns = cat_features, drop_first=True)\n",
    "print data_train.shape\n",
    "print data_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посольку не все категории у категориальных признаков могут встречаться в обоих датасетах, нужно добавить недостающие признаки с нулевыми значениями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 386)\n",
      "(10000, 386)\n"
     ]
    }
   ],
   "source": [
    "cols = data_test.columns\n",
    "for col in cols:\n",
    "    if not col in data_train.columns:\n",
    "        data_test = data_test.drop(col, axis=1)\n",
    "for col in data_train.columns:\n",
    "    if not col in data_test.columns:\n",
    "        data_test[col] = [0]*data_test.shape[0]\n",
    "print data_train.shape\n",
    "print data_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Обучение моделей и анализ результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.cross_validation import cross_val_score, StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценим значение метрики ROC AUC (она используется в kaggle соревновании) для трех моделей по кросс-валидации с 5 фолдами со стратификацией."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "models = [LogisticRegression(), RandomForestClassifier(), GradientBoostingClassifier()]\n",
    "X = data_train.drop('label', axis=1)\n",
    "y = data_train.label\n",
    "scores = []\n",
    "for model in models:\n",
    "    score = cross_val_score(model, X, y, scoring='roc_auc', cv=StratifiedKFold(y, n_folds=5))\n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores \n",
      " Logistic regression: 0.639065024784 \n",
      " Random forest: 0.573178597222 \n",
      " Gradient boosting classifier: 0.715718588661\n"
     ]
    }
   ],
   "source": [
    "print \"Scores \\n Logistic regression: {} \\n Random forest: {} \\n Gradient boosting classifier: {}\".format(*np.array(scores).mean(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценим то же самое но только по вещественным признакам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "models = [LogisticRegression(), RandomForestClassifier(), GradientBoostingClassifier()]\n",
    "X = data_train[real_features]\n",
    "y = data_train.label\n",
    "scores = []\n",
    "for model in models:\n",
    "    score = cross_val_score(model, X, y, scoring='roc_auc', cv=StratifiedKFold(y, n_folds=5))\n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores \n",
      " Logistic regression: 0.628801703953 \n",
      " Random forest: 0.597401419213 \n",
      " Gradient boosting classifier: 0.713371658397\n"
     ]
    }
   ],
   "source": [
    "print \"Scores \\n Logistic regression: {} \\n Random forest: {} \\n Gradient boosting classifier: {}\".format(*np.array(scores).mean(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получили примерно такой же результат. При этом оказалось, что на тестовой выборке kaggle модель с только вещественными признаками дает лучше результат."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим GradientBoostingClassifier на всей выборке и сделаем предсказания для тестовой выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gb = GradientBoostingClassifier()\n",
    "gb.fit(X, y)\n",
    "y_pred = gb.predict_proba(data_test[real_features])[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запишем предсказания в файл ответа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"Id\": range(data_test.shape[0]), 'result': y_pred})\n",
    "df.to_csv('week4_pred.txt', index=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
