{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Градиентный бустинг своими руками\n",
    "\n",
    "**Внимание:** в тексте задания произошли изменения - поменялось число деревьев (теперь 50), правило изменения величины шага в задании 3 и добавился параметр `random_state` у решающего дерева. Правильные ответы не поменялись, но теперь их проще получить. Также исправлена опечатка в функции `gbm_predict`.\n",
    "\n",
    "В этом задании будет использоваться датасет `boston` из `sklearn.datasets`. Оставьте последние 25% объектов для контроля качества, разделив `X` и `y` на `X_train`, `y_train` и `X_test`, `y_test`.\n",
    "\n",
    "Целью задания будет реализовать простой вариант градиентного бустинга над регрессионными деревьями для случая квадратичной функции потерь."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = load_boston()\n",
    "X = data.data\n",
    "y = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ind_train = int(X.shape[0]*0.75)\n",
    "X_train = X[:ind_train,:]\n",
    "y_train = y[:ind_train]\n",
    "X_test = X[ind_train:,:]\n",
    "y_test = y[ind_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(379L, 13L)\n",
      "(127L, 13L)\n",
      "(506L, 13L)\n"
     ]
    }
   ],
   "source": [
    "print X_train.shape\n",
    "print X_test.shape\n",
    "print X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1\n",
    "\n",
    "Как вы уже знаете из лекций, **бустинг** - это метод построения композиций базовых алгоритмов с помощью последовательного добавления к текущей композиции нового алгоритма с некоторым коэффициентом. \n",
    "\n",
    "Градиентный бустинг обучает каждый новый алгоритм так, чтобы он приближал антиградиент ошибки по ответам композиции на обучающей выборке. Аналогично минимизации функций методом градиентного спуска, в градиентном бустинге мы подправляем композицию, изменяя алгоритм в направлении антиградиента ошибки.\n",
    "\n",
    "Воспользуйтесь формулой из лекций, задающей ответы на обучающей выборке, на которые нужно обучать новый алгоритм (фактически это лишь чуть более подробно расписанный градиент от ошибки), и получите частный ее случай, если функция потерь `L` - квадрат отклонения ответа композиции `a(x)` от правильного ответа `y` на данном `x`.\n",
    "\n",
    "Если вы давно не считали производную самостоятельно, вам поможет таблица производных элементарных функций (которую несложно найти в интернете) и правило дифференцирования сложной функции. После дифференцирования квадрата у вас возникнет множитель 2 — т.к. нам все равно предстоит выбирать коэффициент, с которым будет добавлен новый базовый алгоритм, проигноируйте этот множитель при дальнейшем построении алгоритма."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def new_y(y_true, y_pred):\n",
    "    return y_true-y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2\n",
    "\n",
    "Заведите массив для объектов `DecisionTreeRegressor` (будем их использовать в качестве базовых алгоритмов) и для вещественных чисел (это будут коэффициенты перед базовыми алгоритмами). \n",
    "\n",
    "В цикле от обучите последовательно 50 решающих деревьев с параметрами `max_depth=5` и `random_state=42` (остальные параметры - по умолчанию). В бустинге зачастую используются сотни и тысячи деревьев, но мы ограничимся 50, чтобы алгоритм работал быстрее, и его было проще отлаживать (т.к. цель задания разобраться, как работает метод). Каждое дерево должно обучаться на одном и том же множестве объектов, но ответы, которые учится прогнозировать дерево, будут меняться в соответствие с полученным в задании 1 правилом. \n",
    "\n",
    "Попробуйте для начала всегда брать коэффициент равным 0.9. Обычно оправдано выбирать коэффициент значительно меньшим - порядка 0.05 или 0.1, но т.к. в нашем учебном примере на стандартном датасете будет всего 50 деревьев, возьмем для начала шаг побольше.\n",
    "\n",
    "В процессе реализации обучения вам потребуется функция, которая будет вычислять прогноз построенной на данный момент композиции деревьев на выборке `X`:\n",
    "\n",
    "```\n",
    "def gbm_predict(X):\n",
    "    return [sum([coeff * algo.predict([x])[0] for algo, coeff in zip(base_algorithms_list, coefficients_list)]) for x in X]\n",
    "(считаем, что base_algorithms_list - список с базовыми алгоритмами, coefficients_list - список с коэффициентами перед алгоритмами)\n",
    "```\n",
    "\n",
    "Эта же функция поможет вам получить прогноз на контрольной выборке и оценить качество работы вашего алгоритма с помощью `mean_squared_error` в `sklearn.metrics`. \n",
    "\n",
    "Возведите результат в степень 0.5, чтобы получить `RMSE`. Полученное значение `RMSE` — **ответ в пункте 2**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "base_algorithms_list = []\n",
    "coefficients_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gbm_predict(X):\n",
    "    return [sum([coeff * algo.predict([x])[0] for algo, coeff in zip(base_algorithms_list, coefficients_list)]) for x in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DecisionTreeRegressor(criterion='mse', max_depth=5, max_features=None,\n",
       "            max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
       "            splitter='best'),\n",
       " DecisionTreeRegressor(criterion='mse', max_depth=5, max_features=None,\n",
       "            max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
       "            splitter='best'),\n",
       " DecisionTreeRegressor(criterion='mse', max_depth=5, max_features=None,\n",
       "            max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
       "            splitter='best'),\n",
       " DecisionTreeRegressor(criterion='mse', max_depth=5, max_features=None,\n",
       "            max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
       "            splitter='best'),\n",
       " DecisionTreeRegressor(criterion='mse', max_depth=5, max_features=None,\n",
       "            max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
       "            splitter='best'),\n",
       " DecisionTreeRegressor(criterion='mse', max_depth=5, max_features=None,\n",
       "            max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
       "            splitter='best'),\n",
       " DecisionTreeRegressor(criterion='mse', max_depth=5, max_features=None,\n",
       "            max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
       "            splitter='best'),\n",
       " DecisionTreeRegressor(criterion='mse', max_depth=5, max_features=None,\n",
       "            max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
       "            splitter='best'),\n",
       " DecisionTreeRegressor(criterion='mse', max_depth=5, max_features=None,\n",
       "            max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
       "            splitter='best'),\n",
       " DecisionTreeRegressor(criterion='mse', max_depth=5, max_features=None,\n",
       "            max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
       "            splitter='best'),\n",
       " DecisionTreeRegressor(criterion='mse', max_depth=5, max_features=None,\n",
       "            max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
       "            splitter='best'),\n",
       " DecisionTreeRegressor(criterion='mse', max_depth=5, max_features=None,\n",
       "            max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
       "            splitter='best'),\n",
       " DecisionTreeRegressor(criterion='mse', max_depth=5, max_features=None,\n",
       "            max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
       "            splitter='best'),\n",
       " DecisionTreeRegressor(criterion='mse', max_depth=5, max_features=None,\n",
       "            max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
       "            splitter='best'),\n",
       " DecisionTreeRegressor(criterion='mse', max_depth=5, max_features=None,\n",
       "            max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
       "            splitter='best'),\n",
       " DecisionTreeRegressor(criterion='mse', max_depth=5, max_features=None,\n",
       "            max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
       "            splitter='best'),\n",
       " DecisionTreeRegressor(criterion='mse', max_depth=5, max_features=None,\n",
       "            max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
       "            splitter='best'),\n",
       " DecisionTreeRegressor(criterion='mse', max_depth=5, max_features=None,\n",
       "            max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
       "            splitter='best'),\n",
       " DecisionTreeRegressor(criterion='mse', max_depth=5, max_features=None,\n",
       "            max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
       "            splitter='best'),\n",
       " DecisionTreeRegressor(criterion='mse', max_depth=5, max_features=None,\n",
       "            max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
       "            splitter='best'),\n",
       " DecisionTreeRegressor(criterion='mse', max_depth=5, max_features=None,\n",
       "            max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
       "            splitter='best'),\n",
       " DecisionTreeRegressor(criterion='mse', max_depth=5, max_features=None,\n",
       "            max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
       "            splitter='best'),\n",
       " DecisionTreeRegressor(criterion='mse', max_depth=5, max_features=None,\n",
       "            max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
       "            splitter='best'),\n",
       " DecisionTreeRegressor(criterion='mse', max_depth=5, max_features=None,\n",
       "            max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
       "            splitter='best'),\n",
       " DecisionTreeRegressor(criterion='mse', max_depth=5, max_features=None,\n",
       "            max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
       "            splitter='best'),\n",
       " DecisionTreeRegressor(criterion='mse', max_depth=5, max_features=None,\n",
       "            max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
       "            splitter='best'),\n",
       " DecisionTreeRegressor(criterion='mse', max_depth=5, max_features=None,\n",
       "            max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
       "            splitter='best'),\n",
       " DecisionTreeRegressor(criterion='mse', max_depth=5, max_features=None,\n",
       "            max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
       "            splitter='best'),\n",
       " DecisionTreeRegressor(criterion='mse', max_depth=5, max_features=None,\n",
       "            max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
       "            splitter='best'),\n",
       " DecisionTreeRegressor(criterion='mse', max_depth=5, max_features=None,\n",
       "            max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
       "            splitter='best'),\n",
       " DecisionTreeRegressor(criterion='mse', max_depth=5, max_features=None,\n",
       "            max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
       "            splitter='best'),\n",
       " DecisionTreeRegressor(criterion='mse', max_depth=5, max_features=None,\n",
       "            max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
       "            splitter='best'),\n",
       " DecisionTreeRegressor(criterion='mse', max_depth=5, max_features=None,\n",
       "            max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
       "            splitter='best'),\n",
       " DecisionTreeRegressor(criterion='mse', max_depth=5, max_features=None,\n",
       "            max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
       "            splitter='best'),\n",
       " DecisionTreeRegressor(criterion='mse', max_depth=5, max_features=None,\n",
       "            max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
       "            splitter='best'),\n",
       " DecisionTreeRegressor(criterion='mse', max_depth=5, max_features=None,\n",
       "            max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
       "            splitter='best'),\n",
       " DecisionTreeRegressor(criterion='mse', max_depth=5, max_features=None,\n",
       "            max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
       "            splitter='best'),\n",
       " DecisionTreeRegressor(criterion='mse', max_depth=5, max_features=None,\n",
       "            max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
       "            splitter='best'),\n",
       " DecisionTreeRegressor(criterion='mse', max_depth=5, max_features=None,\n",
       "            max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
       "            splitter='best'),\n",
       " DecisionTreeRegressor(criterion='mse', max_depth=5, max_features=None,\n",
       "            max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
       "            splitter='best'),\n",
       " DecisionTreeRegressor(criterion='mse', max_depth=5, max_features=None,\n",
       "            max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
       "            splitter='best'),\n",
       " DecisionTreeRegressor(criterion='mse', max_depth=5, max_features=None,\n",
       "            max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
       "            splitter='best'),\n",
       " DecisionTreeRegressor(criterion='mse', max_depth=5, max_features=None,\n",
       "            max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
       "            splitter='best'),\n",
       " DecisionTreeRegressor(criterion='mse', max_depth=5, max_features=None,\n",
       "            max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
       "            splitter='best'),\n",
       " DecisionTreeRegressor(criterion='mse', max_depth=5, max_features=None,\n",
       "            max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
       "            splitter='best'),\n",
       " DecisionTreeRegressor(criterion='mse', max_depth=5, max_features=None,\n",
       "            max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
       "            splitter='best'),\n",
       " DecisionTreeRegressor(criterion='mse', max_depth=5, max_features=None,\n",
       "            max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
       "            splitter='best'),\n",
       " DecisionTreeRegressor(criterion='mse', max_depth=5, max_features=None,\n",
       "            max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
       "            splitter='best'),\n",
       " DecisionTreeRegressor(criterion='mse', max_depth=5, max_features=None,\n",
       "            max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
       "            splitter='best'),\n",
       " DecisionTreeRegressor(criterion='mse', max_depth=5, max_features=None,\n",
       "            max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
       "            splitter='best'),\n",
       " DecisionTreeRegressor(criterion='mse', max_depth=5, max_features=None,\n",
       "            max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
       "            splitter='best'),\n",
       " DecisionTreeRegressor(criterion='mse', max_depth=5, max_features=None,\n",
       "            max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
       "            splitter='best')]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_algorithms_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train_pred = np.zeros(y_train.shape)\n",
    "#y_train_true = np.copy(y_train)\n",
    "for i in np.arange(50):\n",
    "    base_algorithms_list.append(DecisionTreeRegressor(max_depth=5, random_state=42))\n",
    "    coefficients_list.append(0.9)\n",
    "    y_train_true = new_y(y_train, y_train_pred)\n",
    "    #print(y_train_pred[:5])\n",
    "    #print(y_train_true[:5])\n",
    "    base_algorithms_list[i].fit(X_train, y_train_true)\n",
    "    y_train_pred = gbm_predict(X_train)\n",
    "    #print(y_train_pred[:5])\n",
    "y_test_pred = gbm_predict(X_test)\n",
    "error = mean_squared_error(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.4766509741689484"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wtite_to_file(task, ans):\n",
    "    with open(\"ass2_\"+str(task)+\".txt\", \"w\") as f:\n",
    "        f.write(str(ans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wtite_to_file(2, np.sqrt(error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 3\n",
    "\n",
    "Вас может также беспокоить, что двигаясь с постоянным шагом, вблизи минимума ошибки ответы на обучающей выборке меняются слишком резко, перескакивая через минимум. \n",
    "\n",
    "Попробуйте уменьшать вес перед каждым алгоритмом с каждой следующей итерацией по формуле `0.9 / (1.0 + i)`, где `i` - номер итерации (от 0 до 49). Используйте качество работы алгоритма как **ответ в пункте 3**. \n",
    "\n",
    "В реальности часто применяется следующая стратегия выбора шага: как только выбран алгоритм, подберем коэффициент перед ним численным методом оптимизации таким образом, чтобы отклонение от правильных ответов было минимальным. Мы не будем предлагать вам реализовать это для выполнения задания, но рекомендуем попробовать разобраться с такой стратегией и реализовать ее при случае для себя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_algorithms_list = []\n",
    "coefficients_list = []\n",
    "y_train_pred = np.zeros(y_train.shape)\n",
    "#y_train_true = np.copy(y_train)\n",
    "for i in np.arange(50):\n",
    "    base_algorithms_list.append(DecisionTreeRegressor(max_depth=5, random_state=42))\n",
    "    coefficients_list.append(0.9/(1+i))\n",
    "    y_train_true = new_y(y_train, y_train_pred)\n",
    "    #print(y_train_pred[:5])\n",
    "    #print(y_train_true[:5])\n",
    "    base_algorithms_list[i].fit(X_train, y_train_true)\n",
    "    y_train_pred = gbm_predict(X_train)\n",
    "    #print(y_train_pred[:5])\n",
    "y_test_pred = gbm_predict(X_test)\n",
    "error = mean_squared_error(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.81089328026\n"
     ]
    }
   ],
   "source": [
    "print np.sqrt(error)\n",
    "wtite_to_file(3, np.sqrt(error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 4\n",
    "\n",
    "Реализованный вами метод - градиентный бустинг над деревьями - очень популярен в машинном обучении. Он представлен как в самой библиотеке `sklearn`, так и в сторонней библиотеке `XGBoost`, которая имеет свой питоновский интерфейс. На практике `XGBoost` работает заметно лучше `GradientBoostingRegressor` из `sklearn`, но для этого задания вы можете использовать любую реализацию. \n",
    "\n",
    "Исследуйте, переобучается ли градиентный бустинг с ростом числа итераций (и подумайте, почему), а также с ростом глубины деревьев. На основе наблюдений выпишите через пробел номера правильных из приведенных ниже утверждений в порядке возрастания номера (это будет **ответ в п.4**):\n",
    "\n",
    "    1. С увеличением числа деревьев, начиная с некоторого момента, качество работы градиентного бустинга не меняется существенно.\n",
    "\n",
    "    2. С увеличением числа деревьев, начиная с некоторого момента, градиентный бустинг начинает переобучаться.\n",
    "\n",
    "    3. С ростом глубины деревьев, начиная с некоторого момента, качество работы градиентного бустинга на тестовой выборке начинает ухудшаться.\n",
    "\n",
    "    4. С ростом глубины деревьев, начиная с некоторого момента, качество работы градиентного бустинга перестает существенно изменяться"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_trees = [2, 5, 10, 20, 30, 40, 50, 100, 200]\n",
    "mean_scores = np.zeros(len(num_trees))\n",
    "mean_scores_test = np.zeros(len(num_trees))\n",
    "for i, num in enumerate(num_trees):\n",
    "    cls = GradientBoostingRegressor(n_estimators=num)\n",
    "    #mean_scores[i] = -cross_val_score(cls, X_train, y_train, cv = 3, scoring=\"mean_squared_error\").mean()\n",
    "    cls.fit(X_train, y_train)\n",
    "    y_pred = cls.predict(X_train)\n",
    "    mean_scores[i] = mean_squared_error(y_train, y_pred)\n",
    "    y_pred = cls.predict(X_test)\n",
    "    mean_scores_test[i] = mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0xb1b2630>]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhIAAAFkCAYAAAB1rtL+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAPYQAAD2EBqD+naQAAIABJREFUeJzt3XmYHWWd9//3t7uTzkJ2yEZIyMIQGBbJgiCiAv4IywBB\nUWkQfHTQcRAvJqMjCi4M+DiIj4KM4KMjLmyZQRFQHyCoMC6gIAQUEdAAEUJIhpCQBEKW7r5/f9Tp\npNPpLH36nFN9znm/rquu7lN1n6pvd6W7P7nrrrsipYQkSVIxGvIuQJIkVS+DhCRJKppBQpIkFc0g\nIUmSimaQkCRJRTNISJKkohkkJElS0QwSkiSpaAYJSZJUNIOEJEkqWo+DREQcGRE/iogXIqI9Ik7u\ntK0pIr4YEX+IiFcLbb4XEeO67KM5Iq6OiBURsTYifhARo0vxBUmSpMoppkdiMPAocC7Q9UEdg4A3\nAP8KHAKcCuwL3N6l3ZXAicA7gbcA44FbiqhFkiTlKHrz0K6IaAfmppR+tIM2s4AHgEkppSURMRR4\nCTg9pXRroc2+wBPAYSmlB4suSJIkVVQlxkgMJ+u5eKXweibQBPy8o0FK6SngOeDwCtQjSZJKpKmc\nO4+IZuAy4KaU0quF1WOBjSmlNV2aLy9s624/o4A5wGJgfXmqlSSpJg0A9gYWpJReLvXOyxYkIqIJ\n+D5Zb8S5vdzdHODGXhclSVL9OhO4qdQ7LUuQ6BQi9gKO7tQbAbAM6B8RQ7v0SowpbOvOYoAbbriB\n/fbbrwwVq9LmzZvHFVdckXcZKiHPaW3xfNaOJ554gve+971Q+FtaaiUPEp1CxBTgqJTSqi5NHgZa\ngWOAzoMtJwK/2c5u1wPst99+zJgxo9QlKwfDhg3zXNYYz2lt8XzWpLIMDehxkIiIwcA0IAqrpkTE\nwcBK4EWy2zjfAPwd0C8ixhTarUwpbUoprYmIa4GvRMQqYC1wFXCfd2xIklRdiumRmAXcSzb2IQFf\nLqz/Htn8EScV1j9aWB+F10cBvyysmwe0AT8AmoG7gI8UUYskScpRj4NESukX7Pi20Z3eUppS2gB8\ntLBIkqQq5bM2lIuWlpa8S1CJeU5ri+dTu8ogoVz4S6r2eE5ri+dTu8ogIUmSimaQkCRJRTNISJKk\nohkkJElS0QwSkiSpaAYJSZJUNIOEJEkqmkFCkiQVzSAhSZKKZpCQJElFM0hIkqSiGSQkSVLRDBKS\nJKloBglJklQ0g4QkSSqaQUKSJBXNICFJkopmkJAkSUUzSEiSpKIZJCRJUtEMEpIkqWgGCUmSVDSD\nhCRJKppBQpIkFc0gIUmSimaQkCRJRTNISJKkohkkJElS0QwSkiSpaAYJSZJUtOoNEr/8JTz5ZN5V\nSJJU16o3SLz//fCd7+RdhSRJda16g8S4cfDii3lXIUlSXTNISJKkolV3kFi6NO8qJEmqa9UdJOyR\nkCQpV9UbJMaPh1WrYP36vCuRJKluVW+QGDcu+7hsWb51SJJUx6o/SHh5Q5Kk3PQ4SETEkRHxo4h4\nISLaI+LkbtpcEhFLI2JdRPw0IqZ12d4cEVdHxIqIWBsRP4iI0T0qxCAhSVLuiumRGAw8CpwLpK4b\nI+IC4DzgQ8ChwGvAgojo36nZlcCJwDuBtwDjgVt6VMWoUdCvn0FCkqQcNfX0DSmlu4C7ACIiumly\nPnBpSuknhTZnA8uBucDNETEU+ABwekrpF4U27weeiIhDU0oP7lIhETB2rEFCkqQclXSMRERMBsYC\nP+9Yl1JaAzwAHF5YNYsswHRu8xTwXKc2u8ZbQCVJylWpB1uOJbvcsbzL+uWFbQBjgI2FgLG9NrvG\nSakkScpVjy9t5GnevHkMGzZsy4o//IGWlGjJryRJkvqM+fPnM3/+/K3WrV69uqzHLHWQWAYEWa9D\n516JMcAjndr0j4ihXXolxhS2bdcVV1zBjBkztqy49FL42tdKULYkSdWvpaWFlpat/3u9cOFCZs6c\nWbZjlvTSRkrpWbIwcEzHusLgyjcC9xdWPQy0dmmzLzAR+E2PDjhuHLz0ErS29q5wSZJUlB73SETE\nYGAaWc8DwJSIOBhYmVJ6nuzWzk9HxCJgMXApsAS4HbLBlxFxLfCViFgFrAWuAu7b5Ts2OowbBynB\n8uWw5549/VIkSVIvFXNpYxZwL9mgygR8ubD+e8AHUkqXR8Qg4BvAcOBXwPEppY2d9jEPaAN+ADST\n3U76kR5X0nlSKoOEJEkVV8w8Er9gJ5dEUkoXAxfvYPsG4KOFpXjObilJUq6q91kbAKNHQ0ODQUKS\npJxUd5BobMzChEFCkqRcVHeQACelkiQpR7URJOyRkCQpF9UfJMaPN0hIkpST6g8S9khIkpSb2ggS\ny5dDe3velUiSVHdqI0i0tsKKFXlXIklS3amNIAFe3pAkKQcGCUmSVLTqDxJjx2YfDRKSJFVc9QeJ\n/v1h1CgnpZIkKQfVHyTAW0AlScpJbQQJJ6WSJCkXtREk7JGQJCkXBglJklS02goSKeVdiSRJdaV2\ngsSGDfDKK3lXIklSXamdIAFe3pAkqcIMEpIkqWi1FSSclEqSpIqqjSAxaBAMHWqPhCRJFVYbQQKc\nlEqSpBzUTpBwLglJkirOICFJkopmkJAkSUUzSEiSpKLVVpB49dVskSRJFVFbQQLslZAkqYIMEpIk\nqWi1FySc3VKSpIqpnSAxdCgMHGiPhCRJFVQ7QSLC2S0lSaqw2gkS4C2gkiRVmEFCkiQVzSAhSZKK\nZpCQJElFq70gsWoVrF+fdyWSJNWF2gsSAMuW5VuHJEl1ojaDhJNSSZJUESUPEhHREBGXRsQzEbEu\nIhZFxKe7aXdJRCwttPlpREzr9cGdJluSpIoqR4/EJ4F/AM4FpgOfAD4REed1NIiIC4DzgA8BhwKv\nAQsion+vjjxqFPTrZ5CQJKlCmsqwz8OB21NKdxVePxcRZ5AFhg7nA5emlH4CEBFnA8uBucDNRR85\nwjs3JEmqoHL0SNwPHBMR+wBExMHAEcAdhdeTgbHAzzvekFJaAzxAFkJ6xyAhSVLFlKNH4jJgKPBk\nRLSRhZWLUkr/Wdg+FkhkPRCdLS9s6x2DhCRJFVOOHon3AGcApwOHAO8D/iUizirDsbZlkJAkqWLK\n0SNxOfBvKaXvF14/HhF7A58CrgeWAQGMYeteiTHAIzva8bx58xg2bNhW61paWmhpadmywiAhSapT\n8+fPZ/78+VutW716dVmPWY4gMQho67KunULvR0rp2YhYBhwD/AEgIoYCbwSu3tGOr7jiCmbMmLHj\no48bBy+9BJs2ZXdwSJJUJ7b5zzWwcOFCZs6cWbZjliNI/Bj4dEQsAR4HZgDzgG91anNloc0iYDFw\nKbAEuL3XRx83DlKC5cthwoRe706SJG1fOYLEeWTB4GpgNLAU+HphHQAppcsjYhDwDWA48Cvg+JTS\nxl4fvfOkVAYJSZLKquRBIqX0GvDPhWVH7S4GLi718Rk/PvvoOAlJksqutp61AbDHHtDQYJCQJKkC\nai9INDZmlzeeey7vSiRJqnm1FyQADj4YFi7MuwpJkmpebQaJ2bPhoYeyuzckSVLZ1GaQmDULVqyA\nv/4170okSapptRskIOuVkCRJZVObQWLs2GwOid/9Lu9KJEmqabUZJGDLOAlJklQ2tRskZs3KgkR7\ne96VSJJUs2o3SMyeDWvWwKJFeVciSVLNqt0g0fGkM8dJSJJUNrUbJEaOhKlTHSchSVIZ1W6QgGyc\nhD0SkiSVTW0Hidmz4ZFHoLU170okSapJtR0kZs2CdevgiSfyrkSSpJpU20FixgyIcJyEJEllUttB\nYsgQmD7dcRKSJJVJbQcJcIZLSZLKqPaDxKxZ8Pvfw8aNeVciSVLNqf0gMXt2FiIeeyzvSiRJqjm1\nHyQOPhiamhwnIUlSGdR+kBg4EA44wHESkiSVQe0HCXCGS0mSyqQ+gsTs2fD449nkVJIkqWTqI0jM\nmgVtbfDoo3lXIklSTamPIHHAAdDc7DgJSZJKrD6CRP/+2d0bjpOQJKmk6iNIgDNcSpJUBvUTJGbN\ngqeegjVr8q5EkqSaUT9BYvZsSAkWLsy7EkmSakb9BInp02HwYMdJSJJUQvUTJBobYcYMx0lIklRC\n9RMkwBkuJUkqsfoKErNnw7PPwssv512JJEk1ob6CxKxZ2Ucvb0iSVBL1FSSmTYNhwwwSkiSVSH0F\niQjHSUiSVEL1FSTAGS4lSSqh+gsSs2bBCy/Aiy/mXYkkSVWv/oLE7NnZR3slJEnqtfoLEnvtBXvs\n4TgJSZJKoCxBIiLGR8T1EbEiItZFxO8jYkaXNpdExNLC9p9GxLRy1NJNcY6TkCSpREoeJCJiOHAf\nsAGYA+wHfAxY1anNBcB5wIeAQ4HXgAUR0b/U9XSr486NlCpyOEmSalVTGfb5SeC5lNI5ndb9tUub\n84FLU0o/AYiIs4HlwFzg5jLUtLXZs2HFCnjuOZg0qeyHkySpVpXj0sZJwEMRcXNELI+IhRGxOVRE\nxGRgLPDzjnUppTXAA8DhZahnWx0zXDpOQpKkXilHkJgC/CPwFHAs8HXgqog4q7B9LJDIeiA6W17Y\nVn5jx8KECY6TkCSpl8pxaaMBeDCl9JnC699HxAHAh4Hre7PjefPmMWzYsK3WtbS00NLS0vOdOcOl\nJKnGzJ8/n/nz52+1bvXq1WU9ZjmCxIvAE13WPQG8o/D5MiCAMWzdKzEGeGRHO77iiiuYMWPGjprs\nutmz4fLLob0dGurvLlhJUu3p7j/XCxcuZObMmWU7Zjn+gt4H7Ntl3b4UBlymlJ4lCxPHdGyMiKHA\nG4H7y1BP92bNgtWrYdGiih1SkqRaU44gcQVwWER8KiKmRsQZwDnA1zq1uRL4dEScFBEHAtcBS4Db\ny1BP93ykuCRJvVbyIJFSegg4FWgBHgMuAs5PKf1npzaXA/8OfIPsbo2BwPEppY2lrme7Ro6EKVMc\nJyFJUi+UY4wEKaU7gDt20uZi4OJyHH+XOcOlJEm9Ut+jDGfNgoULobU170okSapK9R0kZs+Gdevg\nySfzrkSSpKpU30FixozsIV6Ok5AkqSj1HSSGDIHp0x0nIUlSkeo7SIAzXEqS1AsGidmz4fe/h42V\nu/NUkqRaYZA46qgsRHSZm1ySJO1c1QaJRSsXsWTNkt7v6IAD4B3vgM99DjZs6P3+JEmqI1UbJN5+\n3du5+sGrS7Ozz38enn8e/uM/SrM/SZLqRNUGiSkjpvDMK8+UZmf77Qdnn50FitdeK80+JUmqA1Ub\nJCYPn8wzq0oUJAAuvhhWroSvfrV0+5QkqcZVbZCYMmIKz656tnQ7nDQJPvxhuPzyLFBIkqSdqtog\nMXnEZF5+/WXWbFhTup1edFH23I0vfal0+5QkqYZVbZCYMmIKQGl7JcaMgX/6p+zyxosvlm6/kiTV\nqKoNEpOHTwYo7TgJgI9/HAYMyAZeSpKkHaraIDF68GgG9RvEs6+UsEcCYPhw+OQn4ZvfhGdKHFIk\nSaoxVRskIiK7BbTUPRIA550He+yRTVIlSZK2q2qDBJThFtAOgwbBZz4DN94If/xj6fcvSVKNqOog\nMWXElNJf2ujw938PkyfDpz9dnv1LklQDqjpITB4+mWdXPUt7ai/9zvv3h0sugdtvh9/+tvT7lySp\nBlR1kJgyYgob2jaw7NVl5TlASwsceCBceCGkVJ5jSJJUxao+SEAZbgHt0NAA//t/w733ws9+Vp5j\nSJJUxao6SOw9fG+gxJNSdfV3fweHH26vhCRJ3ajqIDG4/2DGDB5Tvh4JgAj4whfgoYfg1lvLdxxJ\nkqpQVQcJyJ65UbLHiW/P294Gxx6b3cHR1lbeY0mSVEWqPkiU/Cmg2/OFL8ATT8D115f/WJIkVYmq\nDxJlm5Sqq5kz4bTTstkuN2wo//EkSaoCVR8kpoyYwtK1S1nfur78B7vkEliyBL7xjfIfS5KkKlAT\nQSKR+Osrfy3/wfbbD973vuyW0FdfLf/xJEnq46o+SHQ8TrxsU2V3dfHF8Mor8NWvVuZ4kiT1YVUf\nJCYMnUBTQ1NlxkkATJwI//iP8KUvwcqVlTmmJEl9VNUHicaGRiYNm1S5IAHZ5FStrfDFL1bumJIk\n9UFVHySgzE8B7c7o0TBvHlx1FSxdWrnjSpLUx9REkKjYLaCdffzjMGgQfP7zlT2uJEl9SE0EiSkj\npvDMqmdIlXwWxrBh8MlPwn/8Bzz9dOWOK0lSH1IzQWLNhjWsWr+qsgc+77zsMsfnPlfZ40qS1EfU\nRJCYPCK7BbTilzcGDoTPfhZuugkee6yyx5YkqQ+oiSAxZcQUoMyPE9+eD3wApkyBiy6q/LElScpZ\nTQSJEQNGMLR5aOV7JAD69cumzv7xj+E3v6n88SVJylFNBImIqPwtoJ2dfjocdFA2v0QlB3xKkpSz\nmggSsOXOjVw0NGTP3/jv/4af/jSfGiRJykHZg0REfDIi2iPiK13WXxIRSyNiXUT8NCKm9eY4k4dP\nzq9HAuDEE+FNb7JXQpJUV8oaJCJiNvAh4Pdd1l8AnFfYdijwGrAgIvoXe6wpI6aw+JXFtLW39aLi\nXoiAL3wBHn4YbrklnxokSaqwsgWJiNgNuAE4B3ily+bzgUtTSj9JKf0ROBsYD8wt9niTh0+mtb2V\nJWuWFLuL3nvrW2HOHPjMZ7JncUiSVOPK2SNxNfDjlNI9nVdGxGRgLPDzjnUppTXAA8DhxR5s8y2g\neV7egKxX4skn4frr861DkqQKKEuQiIjTgTcAn+pm81ggAcu7rF9e2FaUScMnATlMStXVjBnwrnfB\nxRfDhg351iJJUpk1lXqHETEBuBJ4e0ppUyn3PW/ePIYNG7bVupaWFlpaWhjQNIA9h+yZz6RUXV16\nKey/P/zf/wvnn593NZKkOjF//nzmz5+/1brVq1eX9ZhR6gddRcQpwA+BNiAKqxvJeiHagOnAIuAN\nKaU/dHrffwOPpJTmdbPPGcDDDz/8MDNmzNjusd/ynbew17C9uPEdN5boq+mFv//7bJKqp5+GIUPy\nrkaSVKcWLlzIzJkzAWamlBaWev/luLTxM+BAsksbBxeWh8gGXh6cUnoGWAYc0/GGiBgKvBG4vzcH\nnjxict/okYDsQV6rV8OVV+ZdiSRJZVPyIJFSei2l9KfOC9ntnS+nlJ4oNLsS+HREnBQRBwLXAUuA\n23tz7CnDc5yUqquJE+Hcc+H//B946aW8q5EkqSwqNbPlVtdPUkqXA/8OfIPsbo2BwPEppY29Ocjk\nEZNZ/tpyXtv4Wm92UzoXXgiNjTBzJtx1V97VSJJUchUJEimlo1NK/9xl3cUppfEppUEppTkppUW9\nPU7HLaCLX1nc212Vxh57wCOPwPTpcPzx8P73w6pVeVclSVLJ1MyzNiCblAr6wC2gnU2aBAsWwLXX\nwq23wt/+LfzoR3lXJUlSSdRUkBg3ZBzNjc35T0rVVQR84APw+OPZZY5TToEzzoAVK/KuTJKkXqmp\nINEQDUweMblv9Uh0tueeWW/EDTdkvRT77w/f/74P+ZIkVa2aChLQB54CujMRcOaZWe/EkUfCu98N\np50Gy5blXZkkST1Wc0Fiyog+dAvojowdmz0l9Pvfh1/9Khs7ccMN9k5IkqpKzQWJycOzSxulnrGz\nbE47Df70JzjuODjrLDjpJFiS4xNMJUnqgZoLElNGTGHdpnW8tK6KJoHafXe48Ua4/XZYuDDrnbj2\nWnsnJEl9Xk0GCehjt4DuqpNPzsZOvPOdcM45cOyxsHhx3lVJkrRdNRckJo/I5pLoM8/c6KkRI+Db\n385mwnzqKTjwQLjmGmhvz7sySZK2UXNBYmjzUEYNHMWfX/5z3qX0zpw58Mc/wnvfCx/5CBx1FCzq\n9eSfkiSVVM0FCYA37fUm7l18b95l9N7QofD1r8PPfw7PPw8HHQRXXAFtbXlXJkkSUKNBYs7UOdz3\n/H2s3bA271JK4+ij4bHH4EMfgo99LJt/4skn865KkqQaDRLT5tDa3lobvRIdBg+GK6/M5px4+WV4\nwxvgssugtTXvyiRJdawmg8S0kdOYOmIqCxYtyLuU0jviCHj0UTj/fLjoomww5o03erlDkpSLmgwS\nkF3euOvpu/IuozwGDoQvfhF+9zuYOjUbkLn//nDddfZQSJIqqnaDxLQ5PLPqGRatrOE7HWbMgJ/8\nJAsU06fD+96XffzOd2DTpryrkyTVgZoNEkftfRRNDU21eXmjq1mztsyKeeCB2SPL990XvvUt2Lgx\n7+okSTWsZoPEkOYhHLHXESx4ug6CRIdDDoFbb83GUMyYAR/8IPzN38A3v2mgkCSVRc0GCcjGSdy7\n+F42ttXZH9GDD4Yf/CC7ZfSNb4QPfximTcvmpNiwIe/qJEk1pLaDxLQ5vLrxVe5//v68S8nHAQfA\nf/1XNkPmm9+czZA5dSp87Wuwfn3e1UmSakBNB4k3jH0Dewzaoz7GSezI/vvDTTdljys/6qjs1tEp\nU+CrX4XXX8+7OklSFavpINEQDcyZNqe+xknsyPTpcP312ayYxx6bzZI5eTJ85Suwbl3e1UmSqlBN\nBwnIxkk8suwRlr+6PO9S+o599oHvfjd7uuiJJ8InPpEFii99CV59Ne/qJElVpOaDxLFTjwXg7qfv\nzrmSPmjqVLj2WvjLX+CUU+DCC7NAcdllsLZGnlMiSSqrmg8SoweP5pCxh3h5Y0cmT85uEV20CE47\nDT77Wdh7b/jXf4UXXsi7OklSH1bzQQKyyxt3P3037ak971L6tkmTsltEn34aTj89m4Z74kQ46aRs\nwiun35YkdVEfQWLaHF5a9xKPLns071Kqw157wdVXw4svwjXXZB/nzs1CxYUXZkFDkiTqJEi8aa83\nsVv/3bwNtKeGDYN/+Ad46KFs+u13vCMLFtOmwdFHw/z5zkchSXWuLoJE/8b+HLX3UY6T6I1DDskm\nslq6NHvKaFsbnHEGjB+fzUvx2GN5VyhJykFdBAmA46Ydx33P38faDd6N0CuDBsFZZ8EvfpHNR3HO\nOVnPxEEHwWGHZQ8K844PSaobdRMk5kydQ2t7K/cuvjfvUmrHvvvC5ZfDkiVwyy0wciR86ENZL8UH\nPwgPPAAp5V2lJKmM6iZITB05lakjpjpOohz698/GT9xxByxeDB//ONx9d9ZDcdBBcNVVsHJl3lVK\nksqgboIEZL0Sdz19V95l1LaJE+Fzn4NnnoG77sp6LT72sayX4owz4J57oN3bcCWpVjTlXUAlzZk2\nh2seuoZFKxcxbeS0vMupbY2NMGdOtvzP/2QDNL/1LTjmmGxGzfe+N5v0atSoLcvIkTBiBDTV1T9L\nSapqdfUb+6i9j6KpoYkFixYw7VCDRMWMHp1d7vjYx+DXv84CxZVXwurV3bcfPnxLsOgcNLpb1/F6\nyBCIqOzXJUmqryAxpHkIR+x1BAueXsBHDv1I3uXUnwg48shsAdiwIRs78fLLWz52LJ1fP/ccPPro\nltebNm277379toSK7YWN7l43N1f2eyBJNaauggRk4yS+8OsvsLFtI/0b++ddTn1rboZx47JlV6WU\nPaF0Z+Hj5Zfhj3/csu6VV7q/g2Tw4F0LH53XDR+eXbqRJNVfkDhu2nFceM+F3P/8/bxt77flXY56\nKiK7jDFkSDbGYle1tcGqVduGja4BZMUK+POft7xet677GkaM6Fn4GDUqCy1efpFUY+ouSBw89mBG\nDx7NgkULDBL1pLERdt89W3pi/fpd6/145plsKvGObd094Kx//56N++j4vL89Z5L6rroLEg3RwLFT\nj2XB0wv4t7f/W97lqK8bMAD23DNbdlVKsGbNzsPHyy9nk3l1fL69wae77daz8DFqVPaclIa6urtb\nUk5KHiQi4lPAqcB04HXgfuCClNKfu7S7BDgHGA7cB/xjSmlRqevpzpypc7jhDzew/NXljNltTCUO\nqXoSkf0hHzYMJk/e9fe1tmaXX3Z06eXll2H5cvjTn7a87u7BaQ0N2eWXnoSPUaNg4EAvv0jqkXL0\nSBwJ/DvwUGH//wbcHRH7pZReB4iIC4DzgLOBxcDngQWFNhvLUNNWjp16LAB3P303Zx18VrkPJ+2a\npibYY49s6Yl163at92PRomza8o7t3U0M1tzcs3Efo0ZlgaVfv9J8DyRVnZIHiZTSCZ1fR8T/Av4H\nmAn8urD6fODSlNJPCm3OBpYDc4GbS11TV6MHj+aQsYew4OkFBglVv0GDsmXChF1/T3t7dvllZ70f\nK1fCX/+65fX2Hsg2dGh2GaipqTaWfv22v62x0V4bqZNKjJEYDiRgJUBETAbGAj/vaJBSWhMRDwCH\nU4EgAdnljWsfuZb21E5DeC1ZdaahIbuNdfjwbKbRXbVx47aXX1auzJYNG7LLM8Us69YV/96uSyU0\nNuYfdioVnLouDQ0GKW2lrEEiIgK4Evh1SulPhdVjyYLF8i7Nlxe2VcScaXO47L7LeHTZo8wYN6NS\nh5WqW//+MGZMtvRFKWW9LR2hYtOm0gWUci7r15dmP21tlfk+5x18KhmcugtS2kq5eySuAfYHjijz\ncXrsTXu9id3678aCRQsMElKtiMh6Cxob63PW0pSyMNE5XPT1MLVxY+l6pCrxQMCI/INQT5fFi8v6\nLSlbkIiIrwEnAEemlF7stGkZEMAYtu6VGAM8sqN9zps3j2HDhm21rqWlhZaWlh7X17+xP0dPPpoF\nTy/gU0d+qsfvl6Q+p/MfuXrU3r5tkOrrYapUvVGFRwfMLyydbefG8pIpy7+2Qog4BXhrSum5zttS\nSs9GxDLgGOAPhfZDgTcCV+9ov1dccQUzZpSu92DO1Dmcf9f5rN2wliHNQ0q2X0lSDhoasqVe7yJq\nb6eltZWWLiFj4cKFzDz++LIdtuQXeyLiGuBM4AzgtYgYU1gGdGp2JfDpiDgpIg4ErgOWALeXup4d\nmTN1Dq3trdy7+N5KHlaSpNJraMjGMQ0alN1JNXJk9vTl0aPLe9gy7PPDwFDgv4GlnZZ3dzRIKV1O\nNtfEN4AHgIHA8ZWYQ6KzqSOnMnXEVBYsWlDJw0qSVDNKfmkjpbRL4SSldDFwcamP31Nzps7hrqfv\nyrsMSZIF8AKvAAANrUlEQVSqUt3fx3LCPifwzKpnuPnxikxfIUlSTan7IHH8Psdz5oFnctatZ/GL\nxb/IuxxJkqpK3QeJhmjg26d8myMnHsnc/5rL4//zeN4lSZJUNeo+SEA2p8Qt776FicMmctyNx/HC\nmhfyLkmSpKpgkCgYNmAYd555J0Fw/I3Hs3p9uafwkCSp+hkkOhk/ZDx3vfcunl/zPO+4+R1sbKvo\n3aiSJFUdg0QX+++xP7effju/fu7XvP/299OeKjB3uyRJVcog0Y23THoLN5x6A/Mfm8+nfuZzOCRJ\n2p46fbLLzr3rb9/F0rVL+acF/8SEoRP46Bs/mndJkiT1OQaJHTj/sPN5fs3znH/X+YwfMp537v/O\nvEuSJKlPMUjsxOX/3+W8sPYFzvzhmYzZbQxvnvjmvEuSJKnPcIzETjREA9895bscvtfhnDz/ZJ54\n6Ym8S5Ikqc8wSOyC5qZmbn3Prew5dE+Ou/E4lq5dmndJkiT1CQaJXTR8wHDuPPNO2lM7J9x4Ams2\nrMm7JEmScmeQ6IEJQydw55l3sviVxbzz5nc6YZUkqe4ZJHrogNEHcNvpt/HLv/6Sc350DimlvEuS\nJCk3BokivG3vt/G9ud/j+j9cz0X3XJR3OZIk5cbbP4t0+gGn88KaF/j4Tz/OhKETOHf2uXmXJElS\nxRkkeuGfD/9nlqxZwnl3nMf4IeOZO31u3iVJklRRXtrohYjgy3O+zGn7n0bLLS3c//z9eZckSVJF\nGSR6qSEauO7U6zh0z0M5af5JPLXiqbxLkiSpYgwSJTCgaQC3vec2xu42luNuPI5lry7LuyRJkirC\nIFEiIwaO4M4z72Rj20ZOvOlE1m5Ym3dJkiSVnUGihCYOm8idZ97JopWLeNf338Wmtk15lyRJUlkZ\nJErsoDEHcet7buWeZ+/hgz/+oBNWSZJqmkGiDI6efDTfnftdvvf77/HZez+bdzmSJJWN80iUyRkH\nnsGSNUu44GcXcN/z93Hq9FM5ZfopTBw2Me/SJEkqGXskyuhf3vQvXDf3OpqbmvnY3R9j0pWTmPnN\nmVz6i0t5bPljXvaQJFW9qIY/ZhExA3j44YcfZsaMGXmXU5Q1G9Zw51/u5LanbuP//fn/sXbjWqaO\nmMrc6XOZO30uh084nMaGxrzLlCTVmIULFzJz5kyAmSmlhaXev5c2KmRo81Dec8B7eM8B72FD6wbu\nXXwvtz15Gzc+diNf/s2X2WPQHpy878nMnT6XYyYfw8B+A/MuWZKknTJI5KC5qZnjph3HcdOO45oT\nr+HBFx7ktidv49Ynb+XaR65lcL/BHDftOOZOn8uJ+5zIiIEj8i5ZkqRuGSRy1hANHDbhMA6bcBiX\nvf0ynnjpCW578jZue+o2zrr1LJoamnjrpLcyd/pcTtn3FPYatlfeJUuStJljJPqwF9a8wI+e+hG3\nPXUb9zx7D63trcwcN5O50+dy6vRT2X+P/YmIvMuUJPVh5R4jYZCoEq+sf2XzYM07/nIHr258lWkj\np3HkxCPZZ+Q+7DNqH/YZuQ/TRk5jcP/BeZcrSeojHGwpAIYPGE7LgS20HNjC+tb13PPsPdz+5O0s\nXLaQHz7xQ1ZvWL257fgh4zeHis4hY+rIqQzqNyjHr0KSVGsMElVoQNMATtjnBE7Y5wQAUkq8/PrL\n/OXlv/CXlX/Z/PGRZY9w8+M3s3bjlgeITRg6YbshY0DTgLy+JElSlTJI1ICIYPdBu7P7oN05fK/D\nt9qWUuKldS9tEzJ+t/R33PTYTby26bVsHwR7Ddtrq5Cx9/C9GTVoFCMHjty8DGwa6LgMSdJmBoka\nFxGMHjya0YNHc8TEI7ballJi2avLWLRy0VYh4zdLfsP1f7iedZvWbbO/5sZmRgwcsVW4GDlwJCMH\njNx2XWEZMXAEQ5uH0hBOpCpJtcYgUccignFDxjFuyDiOnHTkVttSSqx8fSUrX1/JqvWrNn/e3fLU\niqe2atva3rrNsRqigREDtgSQ4QOGM6jfIJqbmhnQNIABjQOyj52Wzdu6WZobd7CtqdnQIkkVYpBQ\ntyKCUYNGMWrQqB69L6XEqxtf3WHwWPn6Sl7Z8ArrW9ezesNq1reu32rZ0Lph8+evt75Oe2rvcf39\nGvptN2R0G0Aat79tZ6Glu/X9Gvp5CUhSXTBIqKQigiHNQxjSPIRJwydtt938+fNpOaNll/bZ2t66\nTcDYJny07WBb1/e1bfl87Ya1vPTaSzvdX4+/D0TxPSpFBJfu3lfpZ7fMnz+flpZdO6fq+zyf2lW5\nBomI+AjwcWAs8Hvgoyml3+VZkyqjJ7+kmhqa2K3/buzWf7cyV9W9lBIb2zYWF1p2IeysWLdiu9s6\n9repfVOP625qaOpZOGksPrQ0NzXzreu+xWHHHUZjQyON0UhDNGz+vLGh8Lrwecf2hmiw56aPMkho\nV+UWJCLiPcCXgQ8BDwLzgAUR8TcppRV51SV1FZH1LjQ3NTOMYbnU0Nbetk3Y6FUPTademXWb1rHy\n9ZU73N/61vUkdjJ53TMw5aopPf7aOgLGrgSPHW0v5j3bbKd3NZR6ezn2GYThTSWVZ4/EPOAbKaXr\nACLiw8CJwAeAy3OsS+pzGhsaGdQwKLcJxVJKmy8xbS+0XPCrC7jkrEtoS220p3ba2ttoS220tRde\nFz7f3rqdvadH23fQprW9lQ1tG8pSQ3fr+qLOYWN7weOVp19h0pWTKheGcgxs5Q50tT74O5cgERH9\ngJnAFzrWpZRSRPwMOHy7b5SUi4igX2M/+jX2Y0jzkG7bjBo0imOmHFPhyvq+lFL5AlOZ9tme2rnh\nhzfw7oPevcvBbUfH2NS+aXN4q8TX1RflGYZWL1698wJ7Ia8eid2BRmB5l/XLgX27aT8A4Iknnihz\nWaqU1atXs3Bhyad8V448p+UVBE2l+JUdhQWy38Lb8bOmn3Hq8FN7f7wctKd22tvbs2BB2+bPO5a2\n1Gkd7ZtDyFZt2ttop33zvjqCy1b7SFu2d+ynIzh2tOn8urua2trbSKTNNbWlwuvONbV2U1M3NW5M\nG7f9OlIba5dsnt24LNMX5/LQrogYB7wAHJ5SeqDT+i8Cb0kpHd6l/RnAjZWtUpKkmnJmSummUu80\nrx6JFUAbMKbL+jHAsm7aLwDOBBYDPb8XT5Kk+jUA2Jvsb2nJ5fYY8Yj4LfBASun8wusAngOuSil9\nKZeiJElSj+R518ZXgO9GxMNsuf1zEPDdHGuSJEk9kFuQSCndHBG7A5eQXdJ4FJiTUnopr5okSVLP\n5HZpQ5IkVb/aniVDkiSVlUFCkiQVrSqCRER8JCKejYjXI+K3ETE775q0cxHxuYho77L8qUubSyJi\naUSsi4ifRsS0vOrV1iLiyIj4UUS8UDh3J3fTZofnLyKaI+LqiFgREWsj4gcRMbpyX4U67Ox8RsR3\nuvl5vaNLG89nHxERn4qIByNiTUQsj4hbI+JvumlX9p/RPh8kOj3c63PAIWRPCV1QGKipvu+PZINp\nxxaWN3dsiIgLgPPIHtx2KPAa2bntn0Od2tZgskHQ58K2T+zaxfN3JdkzdN4JvAUYD9xS3rK1HTs8\nnwV3svXPa9fHf3o++44jgX8H3gi8HegH3B0RAzsaVOxnNKXUpxfgt8BXO70OYAnwibxrc9npufsc\nsHAH25cC8zq9Hgq8Drw779pdtjlX7cDJPTl/hdcbgFM7tdm3sK9D8/6a6nnZzvn8DvDDHbzH89mH\nF7JHT7QDb+60riI/o326R6LTw71+3rEuZV+pD/eqHvsUulKfjogbImIvgIiYTPY/ns7ndg3wAJ7b\nPm8Xz98sslvMO7d5imziOc9x3/S2Qjf5kxFxTUSM7LRtJp7Pvmw4WU/TSqjsz2ifDhLs+OFeYytf\njnrot8D/AuYAHwYmA7+MiMFk5y/hua1Wu3L+xgAbC7+8ttdGfcedwNnA0cAngLcCdxRmHYbsnHk+\n+6DCOboS+HVKqWMcWsV+RvOc2VI1LqXUeV73P0bEg8BfgXcDT+ZTlaTupJRu7vTy8Yh4DHgaeBtw\nby5FaVddA+wPHJHHwft6j0RPH+6lPiyltBr4MzCN7PwFnttqtSvnbxnQPyKG7qCN+qiU0rNkv4M7\nRvl7PvugiPgacALwtpTSi502VexntE8HiZTSJuBh4JiOdYUunGOA+/OqS8WJiN3IfiktLfySWsbW\n53Yo2Qhkz20ft4vn72GgtUubfYGJwG8qVqyKEhETgFFAxx8nz2cfUwgRpwBHpZSe67ytkj+j1XBp\nw4d7VamI+BLwY7LLGXsC/wpsAv6z0ORK4NMRsYjsEfGXkt2Rc3vFi9U2CmNZppH9rwZgSkQcDKxM\nKT3PTs5fSmlNRFwLfCUiVgFrgauA+1JKD1b0i9EOz2dh+RzZbX/LCu2+SNaDuAA8n31NRFxDdnvu\nycBrEdHR87A6pbS+8HllfkbzvmVlF29rObfwTXidLCXNyrsml106b/ML/2hfJxsFfBMwuUubi8lu\nUVpH9gtrWt51u2w+N28luw2srcvy7V09f0Az2b3uKwq/pL4PjM77a6vHZUfnExgA3EUWItYDzwBf\nB/bwfPbNZTvnsg04u0u7sv+M+tAuSZJUtD49RkKSJPVtBglJklQ0g4QkSSqaQUKSJBXNICFJkopm\nkJAkSUUzSEiSpKIZJCRJUtEMEpIkqWgGCUmSVDSDhCRJKtr/DybWo8FKOHXoAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xb1b2518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(num_trees, mean_scores, c=\"g\")\n",
    "plt.plot(num_trees, mean_scores_test, c=\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "depths = [1, 2, 3, 4, 5, 10, 20, 30, 40, 50]\n",
    "mean_scores = np.zeros(len(depths))\n",
    "mean_scores_test = np.zeros(len(depths))\n",
    "for i, num in enumerate(depths):\n",
    "    cls = GradientBoostingRegressor(n_estimators=50, max_depth=num)\n",
    "    #mean_scores[i] = -cross_val_score(cls, X_train, y_train, cv = 3, scoring=\"mean_squared_error\").mean()\n",
    "    cls.fit(X_train, y_train)\n",
    "    y_pred = cls.predict(X_train)\n",
    "    mean_scores[i] = mean_squared_error(y_train, y_pred)\n",
    "    y_pred = cls.predict(X_test)\n",
    "    mean_scores_test[i] = mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0xb9c7470>]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgUAAAFkCAYAAACw3EhvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n1aRe8UE4luYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xb9c70b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(depths, mean_scores, c=\"g\")\n",
    "plt.plot(depths, mean_scores_test, c=\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wtite_to_file(4, \"2 3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 5\n",
    "\n",
    "Сравните получаемое с помощью градиентного бустинга качество с качеством работы линейной регрессии. \n",
    "\n",
    "Для этого обучите `LinearRegression` из `sklearn.linear_model` (с параметрами по умолчанию) на обучающей выборке и оцените для прогнозов полученного алгоритма на тестовой выборке `RMSE`. Полученное качество - ответ в **пункте 5**. \n",
    "\n",
    "В данном примере качество работы простой модели должно было оказаться хуже, но не стоит забывать, что так бывает не всегда. В заданиях к этому курсу вы еще встретите пример обратной ситуации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lnr = LinearRegression()\n",
    "lnr.fit(X_train, y_train)\n",
    "y_pred = lnr.predict(X_test)\n",
    "error = mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.270468034938304"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wtite_to_file(5, np.sqrt(error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
